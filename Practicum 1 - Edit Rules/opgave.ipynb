{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practicum 1: Edit regels voor categorische data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introductie\n",
    "\n",
    "<!--Tijdens het eerste practicum hebben jullie kennis kunnen maken met de eerste 2 V's die Big Data karakteriseert: *Volume* en *Velocity*.\n",
    "Tijdens dit practicum focussen we op *Variety* en *Veracity*.-->\n",
    "\n",
    "<!--Het variÃ«teitsprobleem heeft betrekking op de grote verscheidenheid aan structuren waarin data te vinden zijn.\n",
    "Zo kan het zijn dat data niet voldoen aan een voorgedefinieerd schema waardoor opslag in een relationele database zeer lastig is (zie vorig practicum).\n",
    "Daarnaast is het mogelijk dat verschillende bronnen dezelfde informatie op verschillende manieren opslaan, waardoor uitwisseling, integratie en opslag veel werk vereist.\n",
    "Tot slot is het mogelijk dat data semi- tot ongestructureerd zijn (bvb. tekstuele data of multimedia).-->\n",
    "\n",
    "<!--Een andere grote vraag in de wereld van Big Data is hoe waarheidsgetrouw de data zijn.\n",
    "De enorme overvloed aan data zorgt ervoor dat manuele controle van de kwaliteit lastig is.\n",
    "Data-kwaliteit wordt vaak gedefinieerd aan de hand van verschillende dimensies: compleetheid (hoe volledig zijn de data?), consistentie (brengen de data binnen een systeem dezelfde informatie voort?), accuraatheid (hoe nauwkeurig weerspiegelen de data de werkelijkheid?), tijdigheid (hoe up-to-date zijn de data nog op dit moment?),...\n",
    "Hoe beter de kwaliteit van de data, hoe nauwkeuriger en vollediger de analyses met behulp van deze data kunnen gebeuren.-->\n",
    "\n",
    "Tijdens de theorielessen hebben jullie heel wat materiaal aangerijkt gekregen in verband met edit regels.\n",
    "In de volgende twee oefeningenlessen gaan we praktisch aan de slag met edit regels voor respectievelijk categorische en continue data.\n",
    "\n",
    "In dit eerste practicum bekijken we een kleine dataset die handelt over klinische studies.\n",
    "Deze dataset bestaat uit attributen afkomstig van twee verschillende databronnen namelijk [EudraCT](https://eudract.ema.europa.eu/) en [ClinicalTrials.gov](https://clinicaltrials.gov/).\n",
    "We proberen met behulp van het Fellegi-Holt framework inconsistenties op basis van edit regels op te sporen tussen deze databronnen.\n",
    "In een later practicum is het dan de bedoeling om deze inconsistenties te gaan wegwerken met als doel de kwaliteit van de data te verbeteren.\n",
    "\n",
    "Vooraleer we beginnen, maken we eerst even kennis met de pandas library, die een groot aantal functionaliteiten aanbiedt voor het verwerken en analyseren van gegevens.\n",
    "Deze library zullen we gedurende dit en een aantal van de volgende practica gebruiken.\n",
    "\n",
    "<!--In dit eerste practicum gaan we dieper in op de consistentie van data door data uit verschillende klinische studie-databronnen te gaan analyseren.\n",
    "We zullen ons hierbij vooral richten op de consistentie van data over 2 databronnen, namelijk [EudraCT](https://eudract.ema.europa.eu/) en [ClinicalTrials.gov](https://clinicaltrials.gov/).\n",
    "In eerste instantie zullen we stap voor stap concepten aanrijken om inconsistenties in en tussen databronnen op te sporen.\n",
    "Daarnaast zullen we ook een aantal technieken bekijken om deze inconsistenties weg te werken met als doel de kwaliteit van de data te verbeteren.-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Kennismaking met pandas\n",
    "\n",
    "In dit practicum maken we gebruik van de [pandas](https://pandas.pydata.org/) library van Python.\n",
    "Deze library wordt voornamelijk gebruikt voor het inlezen en analyseren van databronnen.\n",
    "Om jullie enige voeling te doen krijgen met deze library, starten we met een aantal pandas-gebaseerde opdrachten.\n",
    "Door middel van deze opdrachten maken jullie ook stap voor stap kennis met de dataset (clinical_trials_1.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht: lees de dataset 'clinical_trials_1.csv' in met behulp van pandas\n",
    "dataset = pd.read_csv('clinical_trials_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals jullie kunnen zien is het zeer eenvoudig om een .csv bestand in te lezen met pandas.\n",
    "Bij het inlezen van dit bestand wordt er een pandas DataFrame object aangemaakt dat simpelweg een tabel voorstelt met rijen en kolommen die overeenkomen met respectievelijk de rijen en kolommen van het ingeladen .csv bestand.\n",
    "We bekijken dit DataFrame object even van naderbij."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 35945\n",
      "Number of columns: 4\n"
     ]
    }
   ],
   "source": [
    "# Opdracht: hoeveel rijen en kolommen er aanwezig zijn in het DataFrame object?\n",
    "number_of_rows = len(dataset)\n",
    "print(\"Number of rows: {:d}\".format(number_of_rows))\n",
    "\n",
    "number_of_columns = len(dataset.columns)\n",
    "print(\"Number of columns: {:d}\".format(number_of_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om jullie een idee te geven hoe de dataset eruit ziet en welke waarden en kolommen er gepersisteerd zijn, is het mogelijk om de eerste rijen snel te bekijken.\n",
    "Ook kunnen jullie per kolom uitprinten welke waarden er voorhanden zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First ten rows of the dataset: \n",
      "  open double_blind single_blind masking\n",
      "0  NaN          NaN          NaN       0\n",
      "1  Yes           No           No       2\n",
      "2  Yes          Yes           No      >2\n",
      "3  Yes           No           No       0\n",
      "4   No          Yes           No      >2\n",
      "5  Yes           No           No       0\n",
      "6  Yes           No           No     NaN\n",
      "7  Yes           No           No       0\n",
      "8   No           No          Yes       1\n",
      "9  Yes           No           No       0\n"
     ]
    }
   ],
   "source": [
    "# Opdracht: print de eerste 10 rijen van de dataset uit\n",
    "print(\"First ten rows of the dataset: \")\n",
    "print(dataset.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns and column values: \n",
      "Index(['open', 'double_blind', 'single_blind', 'masking'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Opdracht: welke verschillende kolommen zijn er aanwezig in het DataFrame object en welke waarden zijn er te vinden per kolom?\n",
    "print(\"All columns and column values: \")\n",
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als je de vorige opdracht correct hebt uitgevoerd zal je zien dat er 4 kolommen te vinden zijn: 'open', 'double_blind', 'single_blind' en 'masking'.\n",
    "De eerste 3 kolommen zijn afkomstig uit de [EudraCT](https://eudract.ema.europa.eu/) dataset en 'masking' is afkomstig uit de [ClinicalTrials.gov](https://clinicaltrials.gov/) dataset.\n",
    "Elke rij specifieert de details van het ontwerp van een klinische studie die in beide datasets zijn opgenomen.\n",
    "\n",
    "Vooraleer we verder gaan, geven we jullie een klein overzichtje van de betekenis van de kolommen.\n",
    "\n",
    "* **open**: een studie waarvan zowel de onderzoekers als de proefpersonen weten welke behandeling er wordt toegepast\n",
    "* **single_blind**: een studie waarvan maar 1 van beide partijen (meestal de onderzoekers) weten welke behandeling er wordt toegepast\n",
    "* **double_blind**: een studie waarvan noch de onderzoekers, noch de proefpersonen weten welke behandeling er wordt toegepast\n",
    "* **masking**: categorisch attribuut met betrekking tot de masking/blindness van de klinische studie (0 = Open, 1 = Single, 2 = Double, >2 = Triple/Quadruple)\n",
    "\n",
    "Zoals jullie kunnen zien bevat elk attribuut ook een speciale waarde: NaN. Dit komt overeen met een `null`-waarde en geeft aan dat de data niet voorhanden zijn. Hoe groter het aantal `null`-waarden, hoe minder nauwkeurig analyses op basis van de data de werkelijkheid zullen reflecteren, en hoe nefaster voor een onderzoeker. De volgende opdracht zal jullie duidelijk maken hoeveel attribuutwaarden en rijen een `null`-waarde bevatten.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null-values:\n",
      "5202\n"
     ]
    }
   ],
   "source": [
    "# Opdracht: hoeveel attribuutwaarden komen overeen met null\n",
    "print(\"Number of null-values:\")\n",
    "print(dataset.isnull().sum(axis=0).sum())\n",
    "# 5202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows containing a null-value:\n",
      "2083\n"
     ]
    }
   ],
   "source": [
    "# Opdracht: hoeveel rijen bevatten er een null-waarde\n",
    "print(\"Number of rows containing a null-value:\")\n",
    "print(sum(1 for i in dataset.isnull().sum(axis=1) if i > 0))\n",
    "# 2083"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null-values per attribute:\n",
      "open            1547\n",
      "double_blind    1622\n",
      "single_blind    1779\n",
      "masking          254\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Opdracht: print per attribuut uit hoeveel null-waaarden er zijn\n",
    "print(\"Number of null-values per attribute:\")\n",
    "print(dataset.isnull().sum(axis=0))\n",
    "# 1547,1622,1779,254"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tot slot is het ook mogelijk om bepaalde kolommen en rijen te selecteren die voldoen aan opgegeven criteria.\n",
    "Dit zorgt ervoor dat bepaalde data snel teruggevonden kan worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NaN\n",
      "1    Yes\n",
      "2    Yes\n",
      "3    Yes\n",
      "4     No\n",
      "5    Yes\n",
      "6    Yes\n",
      "7    Yes\n",
      "8     No\n",
      "9    Yes\n",
      "Name: open, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Opdracht: print voor de eerste 10 rijen enkel het 'open' attribuut\n",
    "print(dataset['open'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  double_blind single_blind masking\n",
      "0          NaN          NaN       0\n",
      "1           No           No       2\n",
      "2          Yes           No      >2\n",
      "3           No           No       0\n",
      "4          Yes           No      >2\n",
      "5           No           No       0\n",
      "6           No           No     NaN\n",
      "7           No           No       0\n",
      "8           No          Yes       1\n",
      "9           No           No       0\n"
     ]
    }
   ],
   "source": [
    "# Opdracht: print voor de eerste 10 rijen attributen 2 tot 4\n",
    "print(dataset.head(10).iloc[:,1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open            Yes\n",
      "double_blind     No\n",
      "single_blind     No\n",
      "masking           0\n",
      "Name: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Opdracht: print de data van de rij met index 1000\n",
    "# open            Yes\n",
    "# double_blind     No\n",
    "# single_blind     No\n",
    "# masking           0\n",
    "print(dataset.iloc[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    open double_blind single_blind masking\n",
      "8     No           No          Yes       1\n",
      "15    No           No          Yes       1\n",
      "24    No           No          Yes      >2\n",
      "30    No           No          Yes       2\n",
      "32    No           No          Yes       1\n",
      "33    No           No          Yes       1\n",
      "54    No           No          Yes       1\n",
      "62    No           No          Yes       0\n",
      "88    No           No          Yes       1\n",
      "126   No           No          Yes      >2\n"
     ]
    }
   ],
   "source": [
    "# Opdracht: print de eerste 10 rijen waarin het 'single_blind' attribuut de waarde 'Yes' bevat\n",
    "# rijen 8, 15, 24, 30, 32, 33, 54, 62, 88, 126\n",
    "print(dataset[dataset['single_blind'] == 'Yes'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287\n"
     ]
    }
   ],
   "source": [
    "# Opdracht: print het aantal rijen waarin het 'single_blind' attribuut de waarde 'Yes' bevat en het 'masking' attribuut de waarde '1'\n",
    "# 287\n",
    "print(len(dataset[(dataset['single_blind'] == 'Yes') & (dataset['masking'] == '1')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        open  double_blind  single_blind  masking\n",
      "0      False         False         False     True\n",
      "1       True          True          True     True\n",
      "2       True          True          True     True\n",
      "3       True          True          True     True\n",
      "4       True          True          True     True\n",
      "...      ...           ...           ...      ...\n",
      "35940   True          True          True     True\n",
      "35941   True          True          True     True\n",
      "35942   True          True          True     True\n",
      "35943   True          True          True     True\n",
      "35944   True          True          True     True\n",
      "\n",
      "[35945 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Opdracht: print de eerste 10 rijen die GEEN null-waarden bevatten\n",
    "# 1, 2, 3, 4, 5, 7, 8, 9, 11, 12\n",
    "print(dataset.nnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Edit regels\n",
    "\n",
    "Nu jullie kort kennis gemaakt hebben met de [pandas](https://pandas.pydata.org/) library van Python en met de eerste dataset die we gaan gebruiken tijdens dit practicum, is het tijd om de kwaliteit van deze dataset te gaan bepalen en te verbeteren.\n",
    "We hebben namelijk reeds aangehaald dat de ingeladen dataset bestaat uit data gecombineerd uit 2 verschillende klinische studie-databronnen. In het vervolg onderzoeken we hoe consistent de data binnen (intra-consistentie) en tussen (inter-consistentie) de twee databronnen zijn.\n",
    "\n",
    "Het basisprincipe om de kwaliteit van de dataset (of een deel van de dataset) vast te stellen en van waaruit wij gaan vertrekken is als volgt:\n",
    "* In eerste instantie wordt er een set van regels opgesteld waaraan de data moeten voldoen. Deze regels leggen beperkingen vast op attribuutwaarden, attribuutwaarden-combinates, atttribuut-combinaties en/of de dataset in zijn geheel.\n",
    "* Elke regel kan worden getest ten opzichte van het overeenkomstige object en resulteert in een booleaanse waarde (\"ja, dit object voldoet aan de regel\" of \"neen, dit object voldoet niet aan de regel\").\n",
    "* Hoe minder regels er voldaan zijn, hoe lager de kwaliteit van het object. Indien alle regels voldaan zijn is de kwaliteit van het object perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Definitie\n",
    "\n",
    "In deze sectie zullen wij dit basisprincipe invullen door toepassing van *edit regels* op rijen van de gegeven dataset.\n",
    "Edit regels zijn geÃ¯ntroduceerd door Fellegi & Holt in hun paper: A Systematic Approach to Automatic Edit and Imputation (1976).\n",
    "Een edit regel is een elegante manier om niet-toegestane attribuutwaarde-combinaties voor te stellen.\n",
    "\n",
    "De algemene vorm van een edit regel is als volgt:\n",
    "Een *edit regel* voor een dataset $R$ met attributen $a_1,\\dots,a_k$ is een regel van het type $E_1 \\times \\dots \\times E_k$ waarin elke $E_i$ een niet-lege deelverzameling is van $A_i$ ($A_i$ is het domein van alle mogelijke waarden voor $a_i$). Een edit regel legt met andere woorden een ruimte vast binnen $A_1 \\times \\dots \\times A_k$ van niet-toegestane rijen.\n",
    "Indien een rij voorkomt in deze ruimte voldoet deze rij **NIET** aan de regel, anders wel.\n",
    "\n",
    "Voor de eerste dataset hebben we reeds een verzameling van 8 edit regel vastgelegd. Deze zijn te vinden in onderstaande tabel.\n",
    "\n",
    "| Regel | open      | single_blind | double_blind | masking      |\n",
    "|-------|-----------|--------------|--------------|--------------|\n",
    "| 1     | Yes       | dom(single)  | Yes          | dom(masking) |\n",
    "| 2     | dom(open) | Yes          | Yes          | dom(masking) |\n",
    "| 3     | Yes       | Yes          | dom(double)  | dom(masking) |\n",
    "| 4     | dom(open) | No           | dom(double)  | 1            |\n",
    "| 5     | dom(open) | dom(single)  | No           | 2            |\n",
    "| 6     | dom(open) | dom(single)  | Yes          | 0            |\n",
    "| 7     | dom(open) | Yes          | dom(double)  | 0            |\n",
    "| 8     | dom(open) | dom(single)  | Yes          | 1            |\n",
    "\n",
    "Als voorbeeld bekijken we even regel 1: {Yes} $\\times$ dom(single) $\\times$ {Yes} $\\times$ dom(masking).\n",
    "Deze regel legt vast dat open = 'Yes' en double_blind = 'Yes' **NIET** samen kunnen voorkomen, welke waarde de andere twee attributen ook aannemen (dom(X) verwijst naar het hele domein van attribuut X).\n",
    "Dit houdt semantisch ook steek, aangezien het niet mogelijk is dat een studie zowel 'open' als 'double-blind' is.\n",
    "Bekijk even de andere edit regels en probeer ze semantisch te interpreteren vooraleer je verdergaat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht: tel het aantal rijen uit de dataset die niet voldoen aan edit regel 1 uit bovenstaande tabel\n",
    "failing_rows = # ...\n",
    "print(\"Number of rows failing edit rule 1: {:d}\".format(failing_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In onderstaand stuk code hebben wij voor jullie reeds de 8 gegeven edit regels geÃ¯nitialiseerd. Deze zullen jullie nodig hebben tijdens de rest van dit practicum. Indien een attribuut niet gegeven is in een edit regel, betekent dit dat binnen deze edit regel dit attribuut het volledige attribuut-domein beslaat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_rules = [\n",
    "                {\n",
    "                    'open' : 'Yes',\n",
    "                    'double_blind' : 'Yes'\n",
    "                },\n",
    "                {\n",
    "                    'single_blind' : 'Yes',\n",
    "                    'double_blind' : 'Yes'\n",
    "                },\n",
    "                {\n",
    "                    'open' : 'Yes',\n",
    "                    'single_blind' : 'Yes'\n",
    "                }, \n",
    "                {\n",
    "                    'single_blind' : 'No',\n",
    "                    'masking' : '1'\n",
    "                },\n",
    "                {\n",
    "                    'double_blind' : 'No',\n",
    "                    'masking' : '2'\n",
    "                },\n",
    "                {\n",
    "                    'double_blind' : 'Yes',\n",
    "                    'masking' : '0'\n",
    "                },\n",
    "                {\n",
    "                    'single_blind' : 'Yes',\n",
    "                    'masking' : '0'\n",
    "                },\n",
    "                {\n",
    "                    'double_blind' : 'Yes',\n",
    "                    'masking' : '1'\n",
    "                }\n",
    "             ]\n",
    "\n",
    "print(\"Edit rules: \")\n",
    "for edit_rule in edit_rules:\n",
    "    print(edit_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht: implementeer een algoritme dat in de violations dictionary per rijnummer opslaat welke edit regels deze rij schendt indien dit er meer dan 0 zijn.\n",
    "\n",
    "def get_violated_rows(dataset, edit_rules):\n",
    "    violations = {}\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "\n",
    "        # debug info\n",
    "        if index % 5000 == 0:\n",
    "            print(index)\n",
    "            \n",
    "        # TO IMPLEMENT...\n",
    "            \n",
    "    return violations\n",
    "\n",
    "violations = get_violated_rows(dataset, edit_rules)\n",
    "print(\"number of violated rows: {:d}\".format(len(violations.keys())))\n",
    "\n",
    "# 1222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht: valideer voor de eerste rij die opgeslagen is in de violations dictionary of je algoritme effectief het juiste resultaat teruggeeft\n",
    "row = next(iter(violations))\n",
    "print(dataset.iloc[row])\n",
    "\n",
    "for edit_rule_index in violations[row]:\n",
    "    print(edit_rules[edit_rule_index - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Complete set van edit regels\n",
    "\n",
    "In de vorige sectie hebben we gekeken naar welke rijen niet voldoen aan de gegeven set van edit regels.\n",
    "In deze sectie gaan we dieper in op localiseren van de mogelijke fouten.\n",
    "\n",
    "Het is eenvoudig te zien dat een rij enkel gerepareerd kan worden als de attribuutwaarde van een attribuut dat *entert* in een edit regel die niet voldaan is wordt aangepast (entert = de set van waarden voor dit attribuut in deze edit regel beslaan **NIET** het volledige domein)\n",
    "\n",
    "Neem als voorbeeld de volgende rij:\n",
    "\n",
    "| open      | single_blind | double_blind | masking      |\n",
    "|-----------|--------------|--------------|--------------|\n",
    "| Yes       | No           | Yes          | 2            |\n",
    "\n",
    "Zoals je kan zien voldoet deze regel niet aan de edit regel 1: {Yes} $\\times$ dom(single) $\\times$ {Yes} $\\times$ dom(masking).\n",
    "In deze edit regel zien we dat de attributen 'open' en 'double_blind' enteren aangezien de waarden voor deze attributen een echte deelverzameling vormen van de domeinen.\n",
    "Om ervoor te zorgen dat bovenstaande rij voldoet aan deze edit regel is het dus noodzakelijk om ofwel de waarde voor het attribuut 'open' ofwel de waarde voor attribuut 'double_blind' aan te passen.\n",
    "\n",
    "Als we de waarde van het attribuut 'open' veranderen naar 'No' krijgen we volgende rij:\n",
    "\n",
    "| open      | single_blind | double_blind | masking      |\n",
    "|-----------|--------------|--------------|--------------|\n",
    "| No        | No           | Yes          | 2            |\n",
    "\n",
    "Het is duidelijk dat deze rij voldoet aan edit regel 1.\n",
    "Bovendien voldoet deze rij ook aan alle andere gegeven edit regels.\n",
    "\n",
    "Stel daarentegen dat we de waarde van het attribuut 'double_blind' veranderen naar 'No' in de oorspronkelijke rij.\n",
    "Dan verkrijgen we de volgende rij:\n",
    "\n",
    "| open      | single_blind | double_blind | masking      |\n",
    "|-----------|--------------|--------------|--------------|\n",
    "| Yes       | No           | No           | 2            |\n",
    "\n",
    "Ook deze rij voldoet aan edit regel 1.\n",
    "Als we deze rij opnieuw controleren voor de hele gegeven verzameling zien we dat deze rij NIET voldoet aan edit regel 5: dom(open) $\\times$ dom(single) $\\times$ {No} $\\times$ {2}.\n",
    "Dit geeft dus opnieuw probleem.\n",
    "\n",
    "De reden dat dit opnieuw een probleem geeft is omdat edit regels 1 & 5 niet onafhankelijk zijn van elkaar.\n",
    "Aangezien edit regel 1 vermeldt dat 'open' = 'Yes' en double_blind = 'Yes' niet samen mogen voorkomen, mag 'open' = 'Yes' dus enkel met 'double_blind' = 'No' voorkomen.\n",
    "Edit regel 5 vertelt ons dat 'double_blind' = 'No' niet met 'masking' = '2' mag voorkomen.\n",
    "Dit impliceert dus ook dat open = 'Yes' niet met masking = '2' mag voorkomen.\n",
    "We kunnen dus een nieuwe geÃ¯mpliceerde edit regel afleiden uit deze twee regels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formeel definiÃ«ren we dit als volgt:\n",
    "\n",
    "Neem een verzameling $\\mathbb{E}$ bestaande uit minstens 2 edit regels (contributing set) en een attribuut $g$ (generator-attribuut).\n",
    "Construeer een nieuwe edit regel $E_1^* \\times \\cdots \\times E_k^*$ zo dat $E_i^*$ bestaat uit:\n",
    "* de unie van attribuutwaarden van de regels in $\\mathbb{E}$ voor attribuut $g$\n",
    "* de doorsnede van attribuutwaarden van de regels in $\\mathbb{E}$ voor alle andere attributen\n",
    "\n",
    "Als geen enkele $E_i^*$ leeg is, is $E_1^* \\times \\cdots \\times E_k^*$ een *geÃ¯mpliceerde regel*.\n",
    "\n",
    "Indien bovendien het attribuut $g$ entert in elke regel in $\\mathbb{E}$ en $g$ niet entert in de geÃ¯mpliceerde regel, dan is de geÃ¯mpliceerde regel *essentieel nieuw*.\n",
    "\n",
    "De verzameling van gegeven edit regels tesamen met de essentieel nieuwe edit regels wordt de *complete set* van edit regels genoemd.\n",
    "Deze complete set zal, zoals bewezen door Fellegi & Holt, steeds een oplossing bieden voor het localiseren van de fout en zal dus ook steeds een mogelijke reparatie voorstellen.\n",
    "\n",
    "Probeer de definitie van een essentieel nieuw geÃ¯mpliceerde edit regel te begrijpen vooraleer verder te gaan.\n",
    "Pas de definitie eens toe op bovenstaand voorbeeld.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals jullie uit bovenstaande beschrijving begrijpen is het belangrijk om de complete set van edit regels te vinden om het fout-localisatie probleem op te lossen. \n",
    "Doe dit manueel voor de gegeven set met behulp van het Field Code Forest algoritme, geÃ¯ntroduceerd in de theorielessen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Opdracht: vind MANUEEL mbv het Field Code Forest algoritme alle essentieel nieuwe edit regels en voeg ze toe aan de gegeven set van edit regels (de eerste is reeds gegeven in bovenstaande beschrijving)\n",
    "edit_rules.append({'open' : 'Yes', 'masking' : '2'})\n",
    "#edit_rules.append(...)\n",
    "\n",
    "print(\"Edit rules: \")\n",
    "for edit_rule in edit_rules:\n",
    "    print(edit_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht: voeg opnieuw aan de violations dictionary alle rijen toe samen met de regels waaraan ze niet voldoen door uitvoering van het algoritme dat jullie eerder hebben geÃ¯mplementeerd\n",
    "\n",
    "violations = get_violated_rows(dataset, edit_rules)\n",
    "print(\"number of violated rows: {:d}\".format(len(violations.keys())))\n",
    "# 1224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Fout-localisatie\n",
    "\n",
    "Nadat de complete set van edit regels is gegenereerd en per rij de niet-voldane edit regels zijn geÃ¯dentificeerd is het mogelijk om per rij die niet voldoet aan alle regels de fout te gaan localiseren.\n",
    "Dit kan gedaan worden door per rij de minimale covering set van attributen te gaan detecteren. \n",
    "Een minimale covering set moet voldoen aan 2 eigenschappen:\n",
    "* De set is covering: elke niet-voldane edit rule heeft minstens 1 attribuut uit deze set dat entert\n",
    "* De set is minimaal: bij het weglaten van een attribuut verdwijnt de covering eigenschap van dit attribuut\n",
    "\n",
    "Stel dat de dataset volgende rij bevat:\n",
    "\n",
    "| open      | single_blind | double_blind | masking      |\n",
    "|-----------|--------------|--------------|--------------|\n",
    "| No        | Yes          | Yes          | 0            |\n",
    "\n",
    "In de oorspronkelijke (dus niet de complete) verzameling van edit regels zijn er 3 regels waaraan deze rij niet voldoet, namelijk\n",
    "\n",
    "| Regel | open      | single_blind | double_blind | masking      |\n",
    "|-------|-----------|--------------|--------------|--------------|\n",
    "| 2     | dom(open) | Yes          | Yes          | dom(masking) |\n",
    "| 6     | dom(open) | dom(single)  | Yes          | 0            |\n",
    "| 7     | dom(open) | Yes          | dom(double)  | 0            |\n",
    "\n",
    "De minimale sets van attributen die deze regels covert is ofwel {'single_blind', 'double_blind'}, ofwel {'single_blind', 'masking'} ofwel {'double_blind', 'masking'}. \n",
    "Elke niet-voldane regel heeft namelijk minstens 1 attribuut uit deze sets dat entert en deze sets zijn minimaal (je kan er geen attributen uit weglaten zodat de set nog steeds covering is).\n",
    "Uit deze minimale sets kiezen we er een die we gaan gebruiken om de rij te repareren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opdracht: implementeer een algoritme dat voor elke rij eerst de 1-sets van attributen test, dan de 2-sets,... tot er een minimale covering set is gevonden.\n",
    "\n",
    "import itertools\n",
    "\n",
    "def get_minimal_covering_set(violated_rules):\n",
    "    #...\n",
    "    \n",
    "minimal_covering_sets = {}\n",
    "                \n",
    "for row in violations:\n",
    "    minimal_covering_sets[row] = get_minimal_covering_set(violations[row])     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ter info**\n",
    "\n",
    "Het is mogelijk (zoals in bovenstaand voorbeeld) dat er meerdere minimale covering sets van attributen worden gevonden per rij.\n",
    "Om te kiezen welke covering set je dan neemt kan je gaan kijken naar het aantal rijen (de frequenties) die dezelfde attribuutwaarden hebben als de gegeven rij *zonder* de attribuutwaarden van de attributen in de minimale covering set in acht te nemen.\n",
    "Rekening houdend met deze distributie trek je dan willekeurig een minimale covering set die je zal gebruiken om te imputeren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
